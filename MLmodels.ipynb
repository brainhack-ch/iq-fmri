{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import RobustScaler,Normalizer, PowerTransformer,FunctionTransformer, PolynomialFeatures, KBinsDiscretizer\n",
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import sklearn.feature_selection\n",
    "import sklearn.tree\n",
    "import sklearn.svm\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "setup={\n",
    "    \"random_generator\":2,\n",
    "    \"ratio_test_set\":0.15,\n",
    "    \"nr_parallel_processes\":-1, #as much as available \n",
    "    \"max_iter\":1000,\n",
    "    \"numCV\":3,\n",
    "    \"percOfFeaturesToKeep\":[0.2, 0.4, 0.6, 0.8, 1] #if -1 is off\n",
    "}\n",
    "\n",
    "#WHICH MODELS TO TEST \n",
    "allModelTypes=[1,2,4,5,6]\n",
    "\n",
    "#CREATING OUTPUT FOLDER \n",
    "outputFolderName='MLmodelResults'\n",
    "#create folder if doesnt exist \n",
    "try:\n",
    "    os.stat(outputFolderName)\n",
    "except:\n",
    "    os.mkdir(outputFolderName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size: (100, 27)\n",
      "labels size: (100,)\n"
     ]
    }
   ],
   "source": [
    "# loading features\n",
    "fileName=\"features_funcConn_Pearson.csv\"\n",
    "data_path = os.path.abspath(fileName)\n",
    "allData = np.genfromtxt(data_path, delimiter=\",\", skip_header=0)\n",
    "X=allData\n",
    "print('features size: '+str(X.shape))\n",
    "\n",
    "#loading labels\n",
    "fileName=\"IQscores.csv\"\n",
    "data_path = os.path.abspath(fileName)\n",
    "labels = np.genfromtxt(data_path, delimiter=\",\", skip_header=0)\n",
    "Y=labels[:,1]\n",
    "print('labels size: '+ str(Y.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPeople_TrainingSet: 85\n",
      "NumPeople_TestSet: 15\n",
      "x_tr shape:(85, 27)\n",
      "y_tr shape:(85,)\n",
      "x_te shape:(15, 27)\n",
      "y_te shape:(15,)\n"
     ]
    }
   ],
   "source": [
    "#spliting to train and test \n",
    "x_tr, x_te, y_tr, y_te=sklearn.model_selection.train_test_split(X, Y, test_size=setup[\"ratio_test_set\"],  random_state=setup[\"random_generator\"]) \n",
    "numFeatures=x_tr.shape[1]\n",
    "print('NumPeople_TrainingSet: '+ str(x_tr.shape[0]))\n",
    "print('NumPeople_TestSet: '+ str(x_te.shape[0]))\n",
    "print('x_tr shape:' + str(x_tr.shape))\n",
    "print('y_tr shape:' + str(y_tr.shape))\n",
    "print('x_te shape:' + str(x_te.shape))\n",
    "print('y_te shape:' + str(y_te.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to test many different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING\n",
    "def testAllModels(X,Y,allModelTypes):\n",
    "    modelTypeNames=['DecisionTreeRegressor', 'KNeighborsRegressor', 'SVMregression','LinearRegression', 'ElasticNet', 'RidgeRegression', 'Lasso' ]\n",
    "    #spliting to train and test \n",
    "    x_tr, x_te, y_tr, y_te=sklearn.model_selection.train_test_split(X, Y, test_size=setup[\"ratio_test_set\"],  random_state=setup[\"random_generator\"]) \n",
    "    numFeatures=x_tr.shape[1]\n",
    "    for m in range(len(allModelTypes)):\n",
    "\n",
    "        modelType=allModelTypes[m]\n",
    "        print('--> modelType: '+ modelTypeNames[m])\n",
    "        estimators = []\n",
    "        param_grid = {}\n",
    "\n",
    "        #PREPROCESING PIPELINE \n",
    "        preprocess=Pipeline([\n",
    "            ('gauss', PowerTransformer()),\n",
    "            ('scale', RobustScaler(with_scaling=True, with_centering=True)),\n",
    "            #('scale', Normalizer()),\n",
    "            ])\n",
    "        # appending model to pipleline  \n",
    "        estimators.append(('preprocess', preprocess))\n",
    "        #setting parameters for grid search\n",
    "        param_grid[\"preprocess__gauss\"]=[None,PowerTransformer(method='yeo-johnson')]\n",
    "        param_grid[\"preprocess__scale__quantile_range\"]=[(0,1),(0.15,0.85),(0.25,0.75)]\n",
    "        # columns to have latter in export file \n",
    "        colsPreprocess=[\"preprocess__scale__quantile_range\",\"preprocess__gauss\"]\n",
    "\n",
    "         # APPENDING FEATURE SELECTION TO PIPELINE \n",
    "        estimators.append(('feature_selection', sk.feature_selection.SelectKBest()))\n",
    "        param_grid[\"feature_selection__k\"] = [round(numFeatures*x) for x in setup[\"percOfFeaturesToKeep\"]]\n",
    "        param_grid[\"feature_selection__score_func\"]=[sklearn.feature_selection.f_regression,sklearn.feature_selection.mutual_info_regression] #sklearn.feature_selection.chi2,\n",
    "        colsFeatSelect=[\"k\",\"score_func\"]\n",
    "\n",
    "        #SELECTING MODEL AND APPENDING TO PIPELINE\n",
    "        # DecisionTreeRegressor\n",
    "        if (modelType==1):\n",
    "            fileName=\"DecisionTree\"\n",
    "            colsModel=[\"max_depth\",\"min_samples_leaf\",\"max_features\"]\n",
    "            param_grid[\"model__max_depth\"]=[None,2,4,6,8,14,20]\n",
    "            param_grid[\"model__min_samples_leaf\"]=[1,2,3,5,8,14]\n",
    "            param_grid[\"model__max_features\"]=[None,'sqrt','log2']\n",
    "            estimators.append(('model', sklearn.tree.DecisionTreeRegressor( random_state=setup[\"random_generator\"])))\n",
    "        # KNeighborsRegressor\n",
    "        elif (modelType==2):\n",
    "            fileName=\"KNeighbour\"\n",
    "            colsModel=[\"n_neighbors\",\"weights\",\"p\"]\n",
    "            param_grid[\"model__n_neighbors\"]=[2,4,6,10]\n",
    "            param_grid[\"model__weights\"]=['uniform','distance']\n",
    "            param_grid[\"model__p\"]=[1,2]\n",
    "            estimators.append(('model',  sklearn.neighbors.KNeighborsRegressor( algorithm='auto', n_jobs=setup[\"nr_parallel_processes\"])))\n",
    "        #SVR (support vector regression)\n",
    "        elif (modelType==3):\n",
    "            fileName=\"SVMregression\"\n",
    "            colsModel=[\"C\",\"kernel\",\"degree\",\"gamma\"]\n",
    "            param_grid[\"model__C\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            param_grid[\"model__kernel\"]=['rbf','linear', 'poly']\n",
    "            param_grid[\"model__degree\"]=[2,3]\n",
    "            param_grid[\"model__gamma\"]=['auto','scale']\n",
    "            estimators.append(('model',sklearn.svm.SVR( max_iter=setup[\"max_iter\"])))\n",
    "        # linear regression \n",
    "        elif (modelType==4):\n",
    "            fileName=\"LinearRegression\"\n",
    "            estimators.append(('model', sklearn.linear_model.LinearRegression( n_jobs=setup[\"nr_parallel_processes\"])))\n",
    "        # elastic net\n",
    "        elif (modelType==5):\n",
    "            fileName=\"ElasticNet\"\n",
    "            colsModel=[\"alpha\",\"l1_ratio\"] \n",
    "            param_grid[\"model__alpha\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            param_grid[\"model__l1_ratio\"]=[0.3,0.5,0.8]\n",
    "            estimators.append(('model', sklearn.linear_model.ElasticNet( max_iter=setup[\"max_iter\"], random_state=setup[\"random_generator\"])))\n",
    "        #ridge\n",
    "        elif (modelType==6):\n",
    "            fileName=\"RidgeRegression\"\n",
    "            colsModel=[\"alpha\"] \n",
    "            param_grid[\"model__alpha\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            estimators.append(('model',sklearn.linear_model.Ridge( max_iter=setup[\"max_iter\"],  solver='auto', random_state=setup[\"random_generator\"])))\n",
    "        #lasso\n",
    "        elif (modelType==7):\n",
    "            fileName=\"Lasso\"\n",
    "            colsModel=[\"alpha\"] \n",
    "            param_grid[\"model__alpha\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            estimators.append(('model',sklearn.linear_model.Lasso( max_iter=setup[\"max_iter\"], random_state=setup[\"random_generator\"])))\n",
    "\n",
    "\n",
    "\n",
    "        #-------------------------------------------------------------------------------------------\n",
    "        # CREATING FINAL PIPELINE \n",
    "        full_pipeline = Pipeline(estimators)\n",
    "\n",
    "\n",
    "        # GRID SEARCH FOR OPTIMAL PARAMETERS\n",
    "        #setting up score metrics \n",
    "        score=sklearn.metrics.make_scorer(sklearn.metrics.explained_variance_score)  #r2_score\n",
    "        clf = sklearn.model_selection.GridSearchCV(full_pipeline, param_grid, scoring=score, iid=False, n_jobs=-1,cv=setup[\"numCV\"]) # verbose=100\n",
    "        clf = clf.fit(x_tr, y_tr)\n",
    "\n",
    "        #PRINTING PERFORMANCE ON TRAIN AND TEST \n",
    "        #train\n",
    "        pred_tr = clf.predict(x_tr)\n",
    "        print(sklearn.metrics.explained_variance_score(y_tr, pred_tr))  \n",
    "         #test\n",
    "        pred_te = clf.predict(x_te)\n",
    "        print(sklearn.metrics.explained_variance_score(y_te, pred_te))  \n",
    "\n",
    "\n",
    "        #PLOTTING PREDICTION VS TRUE LABELS \n",
    "        #train \n",
    "        plt.figure(1,figsize=(8,5))\n",
    "    #    plt.subplot(2, 3, m+1)\n",
    "        plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "        plt.scatter(y_tr,pred_tr, linestyle='-', marker='o')\n",
    "        plt.grid(True); #plt.axis([1, 8, ymin, ymax]);\n",
    "        plt.ylabel('prediction')\n",
    "        plt.xlabel('true label')\n",
    "        plt.title(fileName+'_train')\n",
    "\n",
    "        #test\n",
    "        plt.figure(2,figsize=(8,5))\n",
    "    #    plt.subplot(2, 3, m+1)\n",
    "        plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "        plt.scatter(y_te,pred_te, linestyle='-', marker='o')\n",
    "        plt.grid(True); #plt.axis([1, 8, ymin, ymax]);\n",
    "        plt.ylabel('prediction')\n",
    "        plt.xlabel('true label')\n",
    "        plt.title(fileName+'_test')\n",
    "\n",
    "\n",
    "        #-------------------------------------------------------------------------------------------\n",
    "        # STORING DATA IN A SUPER NICE WAY!!\n",
    "        #creating columns to keep in final table for .cvs \n",
    "        colsFinal=[]\n",
    "        for c in range(len(colsPreprocess)):\n",
    "            colsFinal=colsFinal+['param_preprocess__'+colsPreprocess[c]]\n",
    "        for c in range(len(colsFeatSelect)):\n",
    "            colsFinal=colsFinal+['param_feature_selection__'+colsFeatSelect[c]]\n",
    "        for c in range(len(colsModel)):\n",
    "            colsFinal=colsFinal+['param_model__'+colsModel[c]]\n",
    "        colsEvaluation=[\"rank_test_score\",\"mean_test_score\",\"mean_train_score\",\"std_test_score\",\"std_train_score\"]\n",
    "        colsFinal=colsFinal+colsEvaluation\n",
    "\n",
    "        #selection columns, sorting and exporting to .csv\n",
    "        df1 = pd.DataFrame(clf.cv_results_,columns=colsFinal)#\n",
    "        df1=df1.sort_values(by=\"mean_test_score\",ascending=False)\n",
    "        df1.to_csv(outputFolderName+ '/AllParameterOptimizing_'+fileName+'.csv')\n",
    "\n",
    "\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQ score num: 18\n",
      "--> modelType: DecisionTreeRegressor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(numSubj,numLabels)=labels.shape\n",
    "allModelTypes=[6]# [1,2,3,4,5,6,7]\n",
    "#for lab in range(0,numLabels):\n",
    "for lab in range(18,26):\n",
    "    print('IQ score num: '+ str(lab))\n",
    "    Y=labels[:,lab]\n",
    "    testAllModels(X,Y,allModelTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
