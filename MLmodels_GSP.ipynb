{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import RobustScaler,Normalizer, PowerTransformer,FunctionTransformer, PolynomialFeatures, KBinsDiscretizer\n",
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import sklearn.feature_selection\n",
    "import sklearn.tree\n",
    "import sklearn.svm\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import scipy.io as SPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to test many different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING\n",
    "def testAllModels(X,Y,allModelTypes,scoreNum):\n",
    "    modelTypeNames=['DecisionTreeRegressor', 'KNeighborsRegressor', 'SVMregression','LinearRegression', 'ElasticNet', 'RidgeRegression', 'Lasso' ]\n",
    "    #spliting to train and test \n",
    "    x_tr, x_te, y_tr, y_te=sklearn.model_selection.train_test_split(X, Y, test_size=setup[\"ratio_test_set\"],  random_state=setup[\"random_generator\"]) \n",
    "    numFeatures=x_tr.shape[1]\n",
    "    #opening .cvs file for that Score\n",
    "    fscores = open(outputFolderNameFinal+\"/IQscore_\"+str(scoreNum)+\"_OptimizedModels.csv\", 'w',newline='')\n",
    "    writerScores = csv.writer(fscores)\n",
    "    #writerScores = csv.writer(open(outputFolderNameFinal+\"/IQscore_\"+str(scoreNum)+\"_OptimizedModels.csv\", 'w'))\n",
    "    \n",
    "    for m in range(len(allModelTypes)):\n",
    "\n",
    "        modelType=allModelTypes[m]\n",
    "        print('--> modelType: '+ modelTypeNames[allModelTypes[m]-1])\n",
    "        estimators = []\n",
    "        param_grid = {}\n",
    "\n",
    "        #PREPROCESING PIPELINE \n",
    "        preprocess=Pipeline([\n",
    "            ('gauss', PowerTransformer()),\n",
    "            #('scale', RobustScaler(with_scaling=True, with_centering=True)),\n",
    "            #('scale', Normalizer()),\n",
    "            ])\n",
    "        # appending model to pipleline  \n",
    "        #setting parameters for grid search\n",
    "        param_grid[\"preprocess__gauss\"]=[None,PowerTransformer(method='yeo-johnson')]\n",
    "        param_grid[\"preprocess__scale__quantile_range\"]=[(0,1),(0.15,0.85),(0.25,0.75)]\n",
    "        # columns to have latter in export file \n",
    "        colsPreprocess=[\"scale__quantile_range\",\"gauss\"]\n",
    "        estimators.append(('preprocess', preprocess))\n",
    "        \n",
    "         # APPENDING FEATURE SELECTION TO PIPELINE \n",
    "        param_grid[\"feature_selection__k\"] = [round(numFeatures*x) for x in setup[\"percOfFeaturesToKeep\"]]\n",
    "        param_grid[\"feature_selection__score_func\"]=[sklearn.feature_selection.f_regression,sklearn.feature_selection.mutual_info_regression] #sklearn.feature_selection.chi2,\n",
    "        colsFeatSelect=[\"k\",\"score_func\"]\n",
    "        estimators.append(('feature_selection', sk.feature_selection.SelectKBest()))\n",
    "\n",
    "        #SELECTING MODEL AND APPENDING TO PIPELINE\n",
    "        # DecisionTreeRegressor\n",
    "        if (modelType==1):\n",
    "            fileName=\"DecisionTree\"\n",
    "            colsModel=[\"max_depth\",\"min_samples_leaf\",\"max_features\"]\n",
    "            param_grid[\"model__max_depth\"]=[None,2,4,6,8,14,20]\n",
    "            param_grid[\"model__min_samples_leaf\"]=[1,2,3,5,8,14]\n",
    "            param_grid[\"model__max_features\"]=[None,'sqrt','log2']\n",
    "            estimators.append(('model', sklearn.tree.DecisionTreeRegressor( random_state=setup[\"random_generator\"])))\n",
    "        # KNeighborsRegressor\n",
    "        elif (modelType==2):\n",
    "            fileName=\"KNeighbour\"\n",
    "            colsModel=[\"n_neighbors\",\"weights\",\"p\"]\n",
    "            param_grid[\"model__n_neighbors\"]=[2,4,6,10]\n",
    "            param_grid[\"model__weights\"]=['uniform','distance']\n",
    "            param_grid[\"model__p\"]=[1,2]\n",
    "            estimators.append(('model',  sklearn.neighbors.KNeighborsRegressor( algorithm='auto', n_jobs=setup[\"nr_parallel_processes\"])))\n",
    "        #SVR (support vector regression)\n",
    "        elif (modelType==3):\n",
    "            fileName=\"SVMregression\"\n",
    "            colsModel=[\"C\",\"kernel\",\"degree\",\"gamma\"]\n",
    "            param_grid[\"model__C\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            param_grid[\"model__kernel\"]=['rbf','linear', 'poly']\n",
    "            param_grid[\"model__degree\"]=[2,3]\n",
    "            param_grid[\"model__gamma\"]=['auto','scale']\n",
    "            estimators.append(('model',sklearn.svm.SVR( max_iter=setup[\"max_iter\"])))\n",
    "        # linear regression \n",
    "        elif (modelType==4):\n",
    "            fileName=\"LinearRegression\"\n",
    "            colsModel=[]\n",
    "            estimators.append(('model', sklearn.linear_model.LinearRegression( n_jobs=setup[\"nr_parallel_processes\"])))\n",
    "        # elastic net\n",
    "        elif (modelType==5):\n",
    "            fileName=\"ElasticNet\"\n",
    "            colsModel=[\"alpha\",\"l1_ratio\"] \n",
    "            param_grid[\"model__alpha\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            param_grid[\"model__l1_ratio\"]=[0.3,0.5,0.8]\n",
    "            estimators.append(('model', sklearn.linear_model.ElasticNet( max_iter=setup[\"max_iter\"], random_state=setup[\"random_generator\"])))\n",
    "        #ridge\n",
    "        elif (modelType==6):\n",
    "            fileName=\"RidgeRegression\"\n",
    "            colsModel=[\"alpha\"] \n",
    "            param_grid[\"model__alpha\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            estimators.append(('model',sklearn.linear_model.Ridge( max_iter=setup[\"max_iter\"],  solver='auto', random_state=setup[\"random_generator\"])))\n",
    "        #lasso\n",
    "        elif (modelType==7):\n",
    "            fileName=\"Lasso\"\n",
    "            colsModel=[\"alpha\"] \n",
    "            param_grid[\"model__alpha\"]=[0.001,0.001,0.01,0.1,1,10,100,1000]\n",
    "            estimators.append(('model',sklearn.linear_model.Lasso( max_iter=setup[\"max_iter\"], random_state=setup[\"random_generator\"])))\n",
    "\n",
    "\n",
    "\n",
    "        #-------------------------------------------------------------------------------------------\n",
    "        # CREATING FINAL PIPELINE \n",
    "        full_pipeline = Pipeline(estimators)\n",
    "\n",
    "\n",
    "        # GRID SEARCH FOR OPTIMAL PARAMETERS\n",
    "        #setting up score metrics \n",
    "        score=sklearn.metrics.make_scorer(sklearn.metrics.r2_score)  # explained_variance_score\n",
    "        clf = sklearn.model_selection.GridSearchCV(full_pipeline, param_grid, scoring=score, iid=False, n_jobs=-1,cv=setup[\"numCV\"]) # verbose=100\n",
    "        clf = clf.fit(x_tr, y_tr)\n",
    "\n",
    "        #PRINTING PERFORMANCE ON TRAIN AND TEST \n",
    "        #train\n",
    "        pred_tr = clf.predict(x_tr)\n",
    "        print(sklearn.metrics.r2_score(y_tr, pred_tr)) \n",
    "        score_tr=sklearn.metrics.r2_score(y_tr, pred_tr)\n",
    "         #test\n",
    "        pred_te = clf.predict(x_te)\n",
    "        print(sklearn.metrics.r2_score(y_te, pred_te))  \n",
    "        score_te=sklearn.metrics.r2_score(y_te, pred_te)\n",
    "\n",
    "        #PLOTTING PREDICTION VS TRUE LABELS \n",
    "        #train \n",
    "        plt.figure(1,figsize=(8,5))\n",
    "    #    plt.subplot(2, 3, m+1)\n",
    "        plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "        plt.scatter(y_tr,pred_tr, linestyle='-', marker='o')\n",
    "        plt.grid(True); #plt.axis([1, 8, ymin, ymax]);\n",
    "        plt.ylabel('prediction')\n",
    "        plt.xlabel('true label')\n",
    "        plt.title(fileName+'_train')\n",
    "\n",
    "        #test\n",
    "        plt.figure(2,figsize=(8,5))\n",
    "    #    plt.subplot(2, 3, m+1)\n",
    "        plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "        plt.scatter(y_te,pred_te, linestyle='-', marker='o')\n",
    "        plt.grid(True); #plt.axis([1, 8, ymin, ymax]);\n",
    "        plt.ylabel('prediction')\n",
    "        plt.xlabel('true label')\n",
    "        plt.title(fileName+'_test')\n",
    "\n",
    "\n",
    "        #-------------------------------------------------------------------------------------------\n",
    "        # STORING DATA IN A SUPER NICE WAY!!\n",
    "        #creating columns to keep in final table for .cvs \n",
    "        colsFinal=[]\n",
    "        for c in range(len(colsPreprocess)):\n",
    "            colsFinal=colsFinal+['param_preprocess__'+colsPreprocess[c]]\n",
    "        for c in range(len(colsFeatSelect)):\n",
    "            colsFinal=colsFinal+['param_feature_selection__'+colsFeatSelect[c]]\n",
    "        for c in range(len(colsModel)):\n",
    "            colsFinal=colsFinal+['param_model__'+colsModel[c]]\n",
    "        colsEvaluation=[\"rank_test_score\",\"mean_test_score\",\"mean_train_score\",\"std_test_score\",\"std_train_score\"]\n",
    "        colsFinal=colsFinal+colsEvaluation\n",
    "\n",
    "        #selection columns, sorting and exporting to .csv\n",
    "        df1 = pd.DataFrame(clf.cv_results_,columns=colsFinal)#\n",
    "        df1=df1.sort_values(by=\"mean_test_score\",ascending=False)\n",
    "        df1.to_csv(outputFolderName+ '/AllParameterOptimizing_'+fileName+'ScoreNum_'+str(scoreNum)+'.csv')\n",
    "\n",
    "        #writing to a file \n",
    "        allResults=[m,modelTypeNames[allModelTypes[m]-1],score_tr,score_te]\n",
    "        writerScores.writerow(allResults)\n",
    "    \n",
    "    \n",
    "    fscores.close()\n",
    "    print('Done!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup={\n",
    "    \"random_generator\":2,\n",
    "    \"ratio_test_set\":0.25,\n",
    "    \"nr_parallel_processes\":-1, #as much as available \n",
    "    \"max_iter\":1000,\n",
    "    \"numCV\":3,\n",
    "    \"percOfFeaturesToKeep\":[0.2, 0.4, 0.6, 0.8, 1] #if -1 is off\n",
    "}\n",
    "\n",
    "#WHICH MODELS TO TEST \n",
    "allModelTypes=[1,2,4,5,6]\n",
    "\n",
    "#CREATING OUTPUT FOLDER \n",
    "outputFolderName='GSP\\MLmodelResults'\n",
    "outputFolderNameFinal='GSP\\MLmodelOptimized'\n",
    "#create folder if doesnt exist \n",
    "try:\n",
    "    os.stat(outputFolderName)\n",
    "except:\n",
    "    os.mkdir(outputFolderName)\n",
    "try:\n",
    "    os.stat(outputFolderNameFinal)\n",
    "except:\n",
    "    os.mkdir(outputFolderNameFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size: (100, 100)\n",
      "labels size: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "# loading features\n",
    "X1 = SPO.loadmat('../data/GSP_PC1.mat')['GSP_PC1'];\n",
    "X2 = SPO.loadmat('../data/GSP_PC2.mat')['GSP_PC2'];\n",
    "# fileName=\"features_funcConn_Pearson_D1D2inTime.csv\"\n",
    "# #fileName=\"features_funcConn_Pearson_D1D2D3D4.csv\"\n",
    "# data_path = os.path.abspath(fileName)\n",
    "# allData = np.genfromtxt(data_path, delimiter=\",\", skip_header=0)\n",
    "# X=allData\n",
    "print('features size: '+str(X1.shape))\n",
    "\n",
    "#loading labels\n",
    "fileName=\"IQscores.csv\"\n",
    "data_path = os.path.abspath(fileName)\n",
    "labels = np.genfromtxt(data_path, delimiter=\",\", skip_header=0)\n",
    "print('labels size: '+ str(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQ score num: 0\n",
      "--> modelType: LinearRegression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter scale for estimator Pipeline(memory=None, steps=[('gauss', None)]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 514, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 147, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 52, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 222, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 147, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 52, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\Users\\Una\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 213, in set_params\n    (key, self))\nValueError: Invalid parameter scale for estimator Pipeline(memory=None, steps=[('gauss', None)]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e950cc1cd8a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtestAllModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallModelTypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2c9db8f75b3e>\u001b[0m in \u001b[0;36mtestAllModels\u001b[1;34m(X, Y, allModelTypes, scoreNum)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# explained_variance_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"numCV\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# verbose=100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m#PRINTING PERFORMANCE ON TRAIN AND TEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter scale for estimator Pipeline(memory=None, steps=[('gauss', None)]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "#SELECT MODELS TO TEST \n",
    "allModelTypes=[4,5,6,7]# [1,2,3,4,5,6,7]\n",
    "(numSubj,numLabels)=labels.shape\n",
    "for score in range(0,numLabels):\n",
    "#for score in range(22,23):\n",
    "    print('IQ score num: '+ str(score))\n",
    "    if (score==0):\n",
    "        X=X1\n",
    "        Y=labels[:,score]\n",
    "    elif(score==1):\n",
    "        X=X2\n",
    "        Y=labels[:,score]\n",
    "    testAllModels(X,Y,allModelTypes, score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
